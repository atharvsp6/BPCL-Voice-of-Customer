{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "562f1da7",
   "metadata": {},
   "source": [
    "## 1. Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aca24fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install transformers torch pandas numpy plotly scikit-learn tqdm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c214077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SENTIMENT ANALYSIS SETUP\n",
      "================================================================================\n",
      "‚úÖ PyTorch version: 2.9.1+cpu\n",
      "‚úÖ Device: CPU\n",
      "‚úÖ All libraries loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import os\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# VADER Sentiment\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SENTIMENT ANALYSIS SETUP (VADER)\")\n",
    "print(\"=\"*80)\n",
    "print(\"‚úÖ NLTK VADER ready\")\n",
    "print(f\"‚úÖ All libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4536244",
   "metadata": {},
   "source": [
    "## 2. Load Topic-Modeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e705fa24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATA LOADED SUCCESSFULLY\n",
      "================================================================================\n",
      "Total Reviews: 82,255\n",
      "\n",
      "Rating Distribution:\n",
      "score\n",
      "1    14913\n",
      "2     2369\n",
      "3     3542\n",
      "4    10036\n",
      "5    51395\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Columns: ['reviewId', 'userName', 'userImage', 'content', 'score', 'thumbsUpCount', 'reviewCreatedVersion', 'at', 'replyContent', 'repliedAt', 'appVersion', 'text_length', 'word_count', 'processed_text', 'dominant_topic', 'topic_probability', 'sentiment_group', 'Topic_Label']\n",
      "\n",
      "Topic-related columns: ['dominant_topic', 'topic_probability', 'Topic_Label']\n"
     ]
    }
   ],
   "source": [
    "# Load the topic-modeled dataset\n",
    "df = pd.read_csv('df_with_topics.csv')\n",
    "\n",
    "# Convert date column\n",
    "if 'at' in df.columns:\n",
    "    df['at'] = pd.to_datetime(df['at'])\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DATA LOADED SUCCESSFULLY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total Reviews: {len(df):,}\")\n",
    "print(f\"\\nRating Distribution:\")\n",
    "print(df['score'].value_counts().sort_index())\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "\n",
    "# Check for topic columns\n",
    "topic_cols = [col for col in df.columns if 'topic' in col.lower()]\n",
    "print(f\"\\nTopic-related columns: {topic_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb00e0a",
   "metadata": {},
   "source": [
    "## 3. Prepare Full Dataset for Analysis\n",
    "**Strategy:** Analyze ALL reviews (100k) for comprehensive insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "558e30e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PREPARING FULL DATASET FOR SENTIMENT ANALYSIS\n",
      "================================================================================\n",
      "üìä Using FULL DATASET: 82,255 reviews\n",
      "   Estimated processing time: ~30-45 minutes (depending on CPU/GPU)\n",
      "\n",
      "‚úÖ Analysis dataset ready!\n",
      "\n",
      "Rating Distribution:\n",
      "score\n",
      "1    14913\n",
      "2     2369\n",
      "3     3542\n",
      "4    10036\n",
      "5    51395\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üí° TIP: Processing will show a progress bar.\n",
      "   You can continue working while it runs in the background.\n"
     ]
    }
   ],
   "source": [
    "# Use full dataset for sentiment analysis\n",
    "print(\"=\"*80)\n",
    "print(\"PREPARING FULL DATASET FOR SENTIMENT ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Option 1: Analyze ALL reviews (recommended for comprehensive insights)\n",
    "USE_FULL_DATASET = True  # Set to False for faster testing with sample\n",
    "\n",
    "if USE_FULL_DATASET:\n",
    "    analysis_df = df.copy()\n",
    "    print(f\"üìä Using FULL DATASET: {len(analysis_df):,} reviews\")\n",
    "    print(f\"   Estimated processing time: ~30-45 minutes (depending on CPU/GPU)\")\n",
    "else:\n",
    "    # Option 2: Use sample for faster testing\n",
    "    one_star = df[df['score'] == 1].copy()\n",
    "    five_star = df[df['score'] == 5].copy()\n",
    "    \n",
    "    SAMPLE_SIZE = 5000\n",
    "    RANDOM_STATE = 42\n",
    "    \n",
    "    five_star_sample = five_star.sample(n=min(SAMPLE_SIZE, len(five_star)), random_state=RANDOM_STATE)\n",
    "    analysis_df = pd.concat([one_star, five_star_sample], ignore_index=True)\n",
    "    analysis_df = analysis_df.sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"üìä Using SAMPLE: {len(analysis_df):,} reviews\")\n",
    "    print(f\"   (1-star: {len(one_star):,}, 5-star sample: {len(five_star_sample):,})\")\n",
    "    print(f\"   Estimated processing time: ~5-10 minutes\")\n",
    "\n",
    "print(f\"\\n‚úÖ Analysis dataset ready!\")\n",
    "print(f\"\\nRating Distribution:\")\n",
    "print(analysis_df['score'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nüí° TIP: Processing will show a progress bar.\")\n",
    "print(f\"   You can continue working while it runs in the background.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c73c52d",
   "metadata": {},
   "source": [
    "## 4. Initialize Sentiment Analysis Pipeline\n",
    "**Model:** VADER (rule-based, fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdf1634d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING VADER SENTIMENT ANALYZER\n",
      "================================================================================\n",
      "\n",
      "‚úÖ VADER initialized successfully!\n",
      "\n",
      "üß™ Test inference: 'This app is amazing!' ‚Üí Positive (compound=0.624)\n"
     ]
    }
   ],
   "source": [
    "# Initialize VADER sentiment analyzer\n",
    "print(\"=\"*80)\n",
    "print(\"LOADING VADER SENTIMENT ANALYZER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "print(\"\\n‚úÖ VADER initialized successfully!\")\n",
    "\n",
    "# Quick test\n",
    "sample_text = \"This app is amazing!\"\n",
    "sample_score = sia.polarity_scores(sample_text)['compound']\n",
    "label = 'Positive' if sample_score >= 0.05 else 'Negative' if sample_score <= -0.05 else 'Neutral'\n",
    "print(f\"\\nüß™ Test inference: '{sample_text}' ‚Üí {label} (compound={sample_score:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d798e0a2",
   "metadata": {},
   "source": [
    "## 5. Batch Sentiment Inference\n",
    "**Efficient processing with progress tracking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d304bb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RUNNING SENTIMENT ANALYSIS (VADER)\n",
      "================================================================================\n",
      "\n",
      "üîÑ Processing 82,255 reviews with VADER (no batching needed)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing sentiment: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 82255/82255 [00:06<00:00, 13228.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Sentiment analysis complete!\n",
      "\n",
      "AI Sentiment Distribution:\n",
      "ai_sentiment\n",
      "Positive    60116\n",
      "Neutral     11303\n",
      "Negative    10836\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def run_sentiment_analysis(texts, pos_thresh=0.05, neg_thresh=-0.05):\n",
    "    \"\"\"\n",
    "    Run VADER sentiment on a list of texts.\n",
    "    Returns labels and compound scores.\n",
    "    \"\"\"\n",
    "    all_labels = []\n",
    "    all_scores = []\n",
    "\n",
    "    # Clean texts (handle NaN and empty strings)\n",
    "    texts = [str(t) if pd.notna(t) and str(t).strip() else \"no content\" for t in texts]\n",
    "\n",
    "    print(f\"\\nüîÑ Processing {len(texts):,} reviews with VADER (no batching needed)...\")\n",
    "\n",
    "    for t in tqdm(texts, desc=\"Analyzing sentiment\"):\n",
    "        scores = sia.polarity_scores(t)\n",
    "        comp = scores['compound']\n",
    "        if comp >= pos_thresh:\n",
    "            label = 'Positive'\n",
    "        elif comp <= neg_thresh:\n",
    "            label = 'Negative'\n",
    "        else:\n",
    "            label = 'Neutral'\n",
    "        all_labels.append(label)\n",
    "        all_scores.append(comp)\n",
    "\n",
    "    return all_labels, all_scores\n",
    "\n",
    "# Run sentiment analysis\n",
    "print(\"=\"*80)\n",
    "print(\"RUNNING SENTIMENT ANALYSIS (VADER)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "texts = analysis_df['content'].tolist()\n",
    "\n",
    "sentiment_labels, sentiment_scores = run_sentiment_analysis(texts)\n",
    "\n",
    "# Add results to dataframe\n",
    "analysis_df['ai_sentiment'] = sentiment_labels\n",
    "analysis_df['ai_confidence'] = np.abs(sentiment_scores)  # use |compound| as confidence proxy\n",
    "analysis_df['ai_compound'] = sentiment_scores\n",
    "\n",
    "print(f\"\\n‚úÖ Sentiment analysis complete!\")\n",
    "print(f\"\\nAI Sentiment Distribution:\")\n",
    "print(analysis_df['ai_sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96640441",
   "metadata": {},
   "source": [
    "## 6. Create Ground Truth Labels\n",
    "**Map star ratings to sentiment categories for validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a5b9ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GROUND TRUTH LABELS CREATED\n",
      "================================================================================\n",
      "\n",
      "Rating ‚Üí Sentiment Mapping:\n",
      "  1-2 stars ‚Üí Negative\n",
      "  3 stars   ‚Üí Neutral\n",
      "  4-5 stars ‚Üí Positive\n",
      "\n",
      "Ground Truth Distribution:\n",
      "rating_sentiment\n",
      "Positive    61431\n",
      "Negative    17282\n",
      "Neutral      3542\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Map star ratings to sentiment\n",
    "def map_rating_to_sentiment(score):\n",
    "    \"\"\"Map star ratings to sentiment categories\"\"\"\n",
    "    if score <= 2:\n",
    "        return 'Negative'\n",
    "    elif score == 3:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'\n",
    "\n",
    "analysis_df['rating_sentiment'] = analysis_df['score'].apply(map_rating_to_sentiment)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GROUND TRUTH LABELS CREATED\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nRating ‚Üí Sentiment Mapping:\")\n",
    "print(\"  1-2 stars ‚Üí Negative\")\n",
    "print(\"  3 stars   ‚Üí Neutral\")\n",
    "print(\"  4-5 stars ‚Üí Positive\")\n",
    "print(\"\\nGround Truth Distribution:\")\n",
    "print(analysis_df['rating_sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f870e87",
   "metadata": {},
   "source": [
    "## 6A. Hybrid Sentiment (VADER + BERT on uncertain rows)\n",
    "**Goal:** Keep VADER for confident rows, run BERT only on uncertain/selected rows, and capture agreement diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85a61612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "HYBRID SENTIMENT (VADER base, BERT on uncertain rows)\n",
      "================================================================================\n",
      "Candidates for BERT refinement: 67,421 rows (82.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Source distribution (VADER vs BERT):\n",
      "hybrid_source\n",
      "BERT     67421\n",
      "VADER    14834\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Agreement: Hybrid vs VADER\n",
      "  Agreement rate: 81.64%\n",
      "  Rows changed by BERT: 15,100\n",
      "\n",
      "Rating alignment (ground truth):\n",
      "  Hybrid accuracy: 88.60%\n",
      "  VADER-only accuracy: 79.24%\n",
      "\n",
      "‚úÖ Hybrid sentiment complete. Added columns: hybrid_sentiment, hybrid_confidence, hybrid_source\n"
     ]
    }
   ],
   "source": [
    "# Hybrid sentiment: VADER baseline + BERT refinement on uncertain/selected rows\n",
    "print(\"=\"*80)\n",
    "print(\"HYBRID SENTIMENT (VADER base, BERT on uncertain rows)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Default to VADER outputs\n",
    "analysis_df['hybrid_sentiment'] = analysis_df['ai_sentiment']\n",
    "analysis_df['hybrid_confidence'] = analysis_df['ai_confidence']\n",
    "analysis_df['hybrid_source'] = 'VADER'\n",
    "\n",
    "# Configuration for refinement\n",
    "CONFIDENCE_MAX = 0.60        # run BERT when |compound| is below this\n",
    "INCLUDE_NEUTRAL = True        # always refine Neutral rows\n",
    "MANUAL_INDEXES = []           # optionally add row indices to force BERT (e.g., [123, 456])\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "candidate_mask = analysis_df['ai_confidence'] <= CONFIDENCE_MAX\n",
    "if INCLUDE_NEUTRAL:\n",
    "    candidate_mask |= analysis_df['ai_sentiment'] == 'Neutral'\n",
    "if MANUAL_INDEXES:\n",
    "    candidate_mask |= analysis_df.index.isin(MANUAL_INDEXES)\n",
    "\n",
    "candidates = analysis_df[candidate_mask].copy()\n",
    "print(f\"Candidates for BERT refinement: {len(candidates):,} rows ({len(candidates)/len(analysis_df)*100:.1f}%)\")\n",
    "\n",
    "if len(candidates) > 0:\n",
    "    from transformers import pipeline\n",
    "\n",
    "    bert_classifier = pipeline(\n",
    "        'text-classification',\n",
    "        model='distilbert-base-uncased-finetuned-sst-2-english',\n",
    "        device=-1  # CPU; change to 0 to force GPU if available\n",
    "    )\n",
    "\n",
    "    bert_preds = []\n",
    "    for start in range(0, len(candidates), BATCH_SIZE):\n",
    "        batch_texts = (\n",
    "            candidates['content']\n",
    "            .iloc[start:start + BATCH_SIZE]\n",
    "            .fillna('no content')\n",
    "            .astype(str)\n",
    "            .tolist()\n",
    "        )\n",
    "        bert_preds.extend(bert_classifier(batch_texts))\n",
    "\n",
    "    bert_labels = ['Positive' if p['label'].upper().startswith('POS') else 'Negative' for p in bert_preds]\n",
    "    bert_scores = [float(p['score']) for p in bert_preds]\n",
    "\n",
    "    candidates.loc[:, 'hybrid_sentiment'] = bert_labels\n",
    "    candidates.loc[:, 'hybrid_confidence'] = bert_scores\n",
    "    candidates.loc[:, 'hybrid_source'] = 'BERT'\n",
    "\n",
    "    # Merge back\n",
    "    analysis_df.loc[candidates.index, ['hybrid_sentiment', 'hybrid_confidence', 'hybrid_source']] = (\n",
    "        candidates[['hybrid_sentiment', 'hybrid_confidence', 'hybrid_source']]\n",
    "    )\n",
    "else:\n",
    "    print(\"No rows met the refinement criteria; hybrid == VADER outputs.\")\n",
    "\n",
    "print(\"\\nSource distribution (VADER vs BERT):\")\n",
    "print(analysis_df['hybrid_source'].value_counts())\n",
    "\n",
    "print(\"\\nAgreement: Hybrid vs VADER\")\n",
    "hybrid_vader_agree = (analysis_df['hybrid_sentiment'] == analysis_df['ai_sentiment']).mean()\n",
    "print(f\"  Agreement rate: {hybrid_vader_agree:.2%}\")\n",
    "print(f\"  Rows changed by BERT: {(~(analysis_df['hybrid_sentiment'] == analysis_df['ai_sentiment'])).sum():,}\")\n",
    "\n",
    "print(\"\\nRating alignment (ground truth):\")\n",
    "hybrid_accuracy = accuracy_score(analysis_df['rating_sentiment'], analysis_df['hybrid_sentiment'])\n",
    "vader_accuracy = accuracy_score(analysis_df['rating_sentiment'], analysis_df['ai_sentiment'])\n",
    "print(f\"  Hybrid accuracy: {hybrid_accuracy:.2%}\")\n",
    "print(f\"  VADER-only accuracy: {vader_accuracy:.2%}\")\n",
    "\n",
    "print(\"\\n‚úÖ Hybrid sentiment complete. Added columns: hybrid_sentiment, hybrid_confidence, hybrid_source\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1918183d",
   "metadata": {},
   "source": [
    "## 7. Model Performance Report\n",
    "**Comparing AI sentiment predictions against actual user ratings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad85b745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MODEL PERFORMANCE REPORT\n",
      "================================================================================\n",
      "\n",
      "üìä OVERALL ACCURACY: 79.24%\n",
      "\n",
      "================================================================================\n",
      "CLASSIFICATION METRICS BY SENTIMENT\n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.86      0.54      0.66     17282\n",
      "     Neutral       0.07      0.23      0.11      3542\n",
      "    Positive       0.92      0.90      0.91     61431\n",
      "\n",
      "    accuracy                           0.79     82255\n",
      "   macro avg       0.62      0.56      0.56     82255\n",
      "weighted avg       0.87      0.79      0.82     82255\n",
      "\n",
      "\n",
      "üéØ AGREEMENT RATE: 79.24%\n",
      "   Reviews where AI agrees with user rating: 65,179\n",
      "   Reviews where AI disagrees: 17,076\n"
     ]
    }
   ],
   "source": [
    "# Calculate performance metrics\n",
    "y_true = analysis_df['rating_sentiment']\n",
    "y_pred = analysis_df['ai_sentiment']\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Classification report\n",
    "class_report = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL PERFORMANCE REPORT\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìä OVERALL ACCURACY: {accuracy:.2%}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLASSIFICATION METRICS BY SENTIMENT\")\n",
    "print(\"=\"*80)\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Agreement analysis\n",
    "analysis_df['sentiment_match'] = analysis_df['ai_sentiment'] == analysis_df['rating_sentiment']\n",
    "match_rate = analysis_df['sentiment_match'].mean()\n",
    "\n",
    "print(f\"\\nüéØ AGREEMENT RATE: {match_rate:.2%}\")\n",
    "print(f\"   Reviews where AI agrees with user rating: {analysis_df['sentiment_match'].sum():,}\")\n",
    "print(f\"   Reviews where AI disagrees: {(~analysis_df['sentiment_match']).sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997badb0",
   "metadata": {},
   "source": [
    "## 8. Confusion Matrix Visualization (Plotly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d3237d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorbar": {
          "title": {
           "text": "Count"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(247,251,255)"
          ],
          [
           0.125,
           "rgb(222,235,247)"
          ],
          [
           0.25,
           "rgb(198,219,239)"
          ],
          [
           0.375,
           "rgb(158,202,225)"
          ],
          [
           0.5,
           "rgb(107,174,214)"
          ],
          [
           0.625,
           "rgb(66,146,198)"
          ],
          [
           0.75,
           "rgb(33,113,181)"
          ],
          [
           0.875,
           "rgb(8,81,156)"
          ],
          [
           1,
           "rgb(8,48,107)"
          ]
         ],
         "hovertemplate": "Actual: %{y}<br>Predicted: %{x}<br>Count: %{z}<extra></extra>",
         "text": [
          [
           "9,322\n(53.9%)",
           "4,877\n(28.2%)",
           "3,083\n(17.8%)"
          ],
          [
           "712\n(20.1%)",
           "827\n(23.3%)",
           "2,003\n(56.5%)"
          ],
          [
           "802\n(1.3%)",
           "5,599\n(9.1%)",
           "55,030\n(89.6%)"
          ]
         ],
         "textfont": {
          "size": 14
         },
         "texttemplate": "%{text}",
         "type": "heatmap",
         "x": [
          "Predicted: Negative",
          "Predicted: Neutral",
          "Predicted: Positive"
         ],
         "y": [
          "Actual: Negative",
          "Actual: Neutral",
          "Actual: Positive"
         ],
         "z": {
          "bdata": "aiQAAA0TAAALDAAAyAIAADsDAADTBwAAIgMAAN8VAAD21gAA",
          "dtype": "i4",
          "shape": "3, 3"
         }
        }
       ],
       "layout": {
        "height": 500,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 16
         },
         "text": "<b>Confusion Matrix: AI Sentiment vs User Ratings</b><br><sub>Overall Accuracy: 79.24% | Agreement Rate: 79.24%</sub>",
         "x": 0.5
        },
        "width": 700,
        "xaxis": {
         "title": {
          "text": "AI Predicted Sentiment"
         }
        },
        "yaxis": {
         "title": {
          "text": "Actual Sentiment (from Rating)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Confusion matrix saved to 'confusion_matrix_data.json'\n"
     ]
    }
   ],
   "source": [
    "# Create confusion matrix\n",
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "# Calculate percentages\n",
    "cm_pct = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "# Create annotation text with counts and percentages\n",
    "annotations = []\n",
    "for i in range(len(labels)):\n",
    "    for j in range(len(labels)):\n",
    "        annotations.append(f\"{cm[i,j]:,}\\n({cm_pct[i,j]:.1f}%)\")\n",
    "\n",
    "annotations = np.array(annotations).reshape(len(labels), len(labels))\n",
    "\n",
    "# Create Plotly heatmap\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=cm,\n",
    "    x=[f'Predicted: {l}' for l in labels],\n",
    "    y=[f'Actual: {l}' for l in labels],\n",
    "    colorscale='Blues',\n",
    "    text=annotations,\n",
    "    texttemplate='%{text}',\n",
    "    textfont={'size': 14},\n",
    "    hovertemplate='Actual: %{y}<br>Predicted: %{x}<br>Count: %{z}<extra></extra>',\n",
    "    colorbar=dict(title='Count')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "        text=f'<b>Confusion Matrix: AI Sentiment vs User Ratings</b><br>' +\n",
    "             f'<sub>Overall Accuracy: {accuracy:.2%} | Agreement Rate: {match_rate:.2%}</sub>',\n",
    "        x=0.5,\n",
    "        font=dict(size=16)\n",
    "    ),\n",
    "    xaxis_title='AI Predicted Sentiment',\n",
    "    yaxis_title='Actual Sentiment (from Rating)',\n",
    "    height=500,\n",
    "    width=700,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Save confusion matrix data for dashboard\n",
    "cm_data = {\n",
    "    'confusion_matrix': cm.tolist(),\n",
    "    'labels': labels,\n",
    "    'accuracy': accuracy,\n",
    "    'match_rate': match_rate,\n",
    "    'classification_report': class_report\n",
    "}\n",
    "\n",
    "with open('confusion_matrix_data.json', 'w') as f:\n",
    "    json.dump(cm_data, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úÖ Confusion matrix saved to 'confusion_matrix_data.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b71a821",
   "metadata": {},
   "source": [
    "## 9. Detailed Disagreement Analysis\n",
    "**Understanding where AI and users disagree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a85cd30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DISAGREEMENT ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Total disagreements: 17,076 (20.8%)\n",
      "\n",
      "Disagreement Patterns:\n",
      "ai_sentiment      Negative  Neutral  Positive    All\n",
      "rating_sentiment                                    \n",
      "Negative                 0     4877      3083   7960\n",
      "Neutral                712        0      2003   2715\n",
      "Positive               802     5599         0   6401\n",
      "All                   1514    10476      5086  17076\n",
      "\n",
      "================================================================================\n",
      "SAMPLE DISAGREEMENTS (for manual review)\n",
      "================================================================================\n",
      "\n",
      "üî¥ 1-Star reviews classified as POSITIVE by AI:\n",
      "\n",
      "  Rating: 1 ‚≠ê | AI: Positive (0.27)\n",
      "  Text: app ui not properly work why account create its this. not processed another step. how many times OTP genrets...\n",
      "\n",
      "  Rating: 2 ‚≠ê | AI: Positive (0.68)\n",
      "  Text: it will be an achievement if I am able to book a cylinder in one go. It needs tons of improvement and optimization...\n",
      "\n",
      "  Rating: 1 ‚≠ê | AI: Positive (0.15)\n",
      "  Text: convenience fee shouldn't be charged....\n",
      "\n",
      "üü¢ 5-Star reviews classified as NEGATIVE by AI:\n",
      "\n",
      "  Rating: 5 ‚≠ê | AI: Negative (0.40)\n",
      "  Text: online login nok book avelable why? regular not work Bharat gas web side/Hello BPCL app very big eshu shollw my problem sir...\n",
      "\n",
      "  Rating: 5 ‚≠ê | AI: Negative (0.09)\n",
      "  Text: Fast Delivery but no contact, they delivery person was don't know our language, delivery report send only delivery day, because,we are not confused delivery note comes two or three days....\n",
      "\n",
      "  Rating: 5 ‚≠ê | AI: Negative (0.34)\n",
      "  Text: not useful...\n"
     ]
    }
   ],
   "source": [
    "# Analyze disagreements\n",
    "disagreements = analysis_df[~analysis_df['sentiment_match']].copy()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DISAGREEMENT ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal disagreements: {len(disagreements):,} ({len(disagreements)/len(analysis_df)*100:.1f}%)\")\n",
    "\n",
    "# Cross-tabulation of disagreements\n",
    "print(\"\\nDisagreement Patterns:\")\n",
    "crosstab = pd.crosstab(\n",
    "    disagreements['rating_sentiment'], \n",
    "    disagreements['ai_sentiment'],\n",
    "    margins=True\n",
    ")\n",
    "print(crosstab)\n",
    "\n",
    "# Sample disagreements\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE DISAGREEMENTS (for manual review)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Show cases where 1-star was classified as Positive\n",
    "false_positives = disagreements[\n",
    "    (disagreements['rating_sentiment'] == 'Negative') & \n",
    "    (disagreements['ai_sentiment'] == 'Positive')\n",
    "]\n",
    "\n",
    "if len(false_positives) > 0:\n",
    "    print(\"\\nüî¥ 1-Star reviews classified as POSITIVE by AI:\")\n",
    "    for idx, row in false_positives.head(3).iterrows():\n",
    "        print(f\"\\n  Rating: {row['score']} ‚≠ê | AI: {row['ai_sentiment']} ({row['ai_confidence']:.2f})\")\n",
    "        print(f\"  Text: {str(row['content'])[:200]}...\")\n",
    "\n",
    "# Show cases where 5-star was classified as Negative\n",
    "false_negatives = disagreements[\n",
    "    (disagreements['rating_sentiment'] == 'Positive') & \n",
    "    (disagreements['ai_sentiment'] == 'Negative')\n",
    "]\n",
    "\n",
    "if len(false_negatives) > 0:\n",
    "    print(\"\\nüü¢ 5-Star reviews classified as NEGATIVE by AI:\")\n",
    "    for idx, row in false_negatives.head(3).iterrows():\n",
    "        print(f\"\\n  Rating: {row['score']} ‚≠ê | AI: {row['ai_sentiment']} ({row['ai_confidence']:.2f})\")\n",
    "        print(f\"  Text: {str(row['content'])[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e5bfaf",
   "metadata": {},
   "source": [
    "## 10. Enrich Full Dataset & Export\n",
    "**Apply sentiment to all reviews and save final dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99305c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PREPARING FINAL ENRICHED DATASET\n",
      "================================================================================\n",
      "\n",
      "Final dataset shape: (82255, 31)\n",
      "\n",
      "Columns in final dataset:\n",
      "  ‚Ä¢ reviewId\n",
      "  ‚Ä¢ userName\n",
      "  ‚Ä¢ userImage\n",
      "  ‚Ä¢ content\n",
      "  ‚Ä¢ score\n",
      "  ‚Ä¢ thumbsUpCount\n",
      "  ‚Ä¢ reviewCreatedVersion\n",
      "  ‚Ä¢ at\n",
      "  ‚Ä¢ replyContent\n",
      "  ‚Ä¢ repliedAt\n",
      "  ‚Ä¢ appVersion\n",
      "  ‚Ä¢ text_length\n",
      "  ‚Ä¢ word_count\n",
      "  ‚Ä¢ processed_text\n",
      "  ‚Ä¢ dominant_topic\n",
      "  ‚Ä¢ topic_probability\n",
      "  ‚Ä¢ sentiment_group\n",
      "  ‚Ä¢ Topic_Label\n",
      "  ‚Ä¢ ai_sentiment\n",
      "  ‚Ä¢ ai_confidence\n",
      "  ‚Ä¢ ai_compound\n",
      "  ‚Ä¢ rating_sentiment\n",
      "  ‚Ä¢ hybrid_sentiment\n",
      "  ‚Ä¢ hybrid_confidence\n",
      "  ‚Ä¢ hybrid_source\n",
      "  ‚Ä¢ sentiment_match\n",
      "  ‚Ä¢ month_year\n",
      "  ‚Ä¢ year\n",
      "  ‚Ä¢ month\n",
      "  ‚Ä¢ month_name\n",
      "  ‚Ä¢ sentiment_score\n"
     ]
    }
   ],
   "source": [
    "# For efficiency, we'll apply sentiment to remaining reviews\n",
    "# Or use the analysis_df directly if full inference isn't needed\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PREPARING FINAL ENRICHED DATASET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Add time-based features for dashboard\n",
    "if 'at' in analysis_df.columns:\n",
    "    analysis_df['month_year'] = analysis_df['at'].dt.to_period('M').astype(str)\n",
    "    analysis_df['year'] = analysis_df['at'].dt.year\n",
    "    analysis_df['month'] = analysis_df['at'].dt.month\n",
    "    analysis_df['month_name'] = analysis_df['at'].dt.month_name()\n",
    "\n",
    "# Ensure topic label column exists\n",
    "if 'dominant_topic' in analysis_df.columns and 'Topic_Label' not in analysis_df.columns:\n",
    "    analysis_df['Topic_Label'] = 'Topic ' + (analysis_df['dominant_topic'] + 1).astype(str)\n",
    "\n",
    "# Create sentiment score (-1 to 1 scale)\n",
    "def calculate_sentiment_score(row):\n",
    "    if row['ai_sentiment'] == 'Positive':\n",
    "        return row['ai_confidence']\n",
    "    elif row['ai_sentiment'] == 'Negative':\n",
    "        return -row['ai_confidence']\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "analysis_df['sentiment_score'] = analysis_df.apply(calculate_sentiment_score, axis=1)\n",
    "\n",
    "print(f\"\\nFinal dataset shape: {analysis_df.shape}\")\n",
    "print(f\"\\nColumns in final dataset:\")\n",
    "for col in analysis_df.columns:\n",
    "    print(f\"  ‚Ä¢ {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27e8cd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXPORT COMPLETE\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Saved: df_final_enriched.csv\n",
      "   Rows: 82,255\n",
      "   Columns: 31\n",
      "\n",
      "üìä Dataset includes:\n",
      "   ‚Ä¢ Original review data (content, score, appVersion, date)\n",
      "   ‚Ä¢ Topic assignments (from LDA model)\n",
      "   ‚Ä¢ AI sentiment labels (Negative/Neutral/Positive)\n",
      "   ‚Ä¢ AI confidence scores\n",
      "   ‚Ä¢ Sentiment scores (-1 to 1)\n",
      "   ‚Ä¢ Time features (month_year, year, month)\n",
      "\n",
      "üéØ Ready for dashboard visualization!\n"
     ]
    }
   ],
   "source": [
    "# Export final enriched dataset\n",
    "OUTPUT_FILE = 'df_final_enriched.csv'\n",
    "\n",
    "analysis_df.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EXPORT COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n‚úÖ Saved: {OUTPUT_FILE}\")\n",
    "print(f\"   Rows: {len(analysis_df):,}\")\n",
    "print(f\"   Columns: {len(analysis_df.columns)}\")\n",
    "print(f\"\\nüìä Dataset includes:\")\n",
    "print(f\"   ‚Ä¢ Original review data (content, score, appVersion, date)\")\n",
    "print(f\"   ‚Ä¢ Topic assignments (from LDA model)\")\n",
    "print(f\"   ‚Ä¢ AI sentiment labels (Negative/Neutral/Positive)\")\n",
    "print(f\"   ‚Ä¢ AI confidence scores\")\n",
    "print(f\"   ‚Ä¢ Sentiment scores (-1 to 1)\")\n",
    "print(f\"   ‚Ä¢ Time features (month_year, year, month)\")\n",
    "print(f\"\\nüéØ Ready for dashboard visualization!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605c2ed1",
   "metadata": {},
   "source": [
    "## 11. Summary Statistics for Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a23d83ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SUMMARY STATISTICS\n",
      "================================================================================\n",
      "\n",
      "üå°Ô∏è GLOBAL SENTIMENT HEALTH: 0.300\n",
      "   Scale: -1 (Very Negative) to +1 (Very Positive)\n",
      "   Interpretation: Positive overall sentiment\n",
      "\n",
      "üìä AI Sentiment by Star Rating:\n",
      "ai_sentiment  Negative  Neutral  Positive\n",
      "score                                    \n",
      "1                 55.6     28.0      16.4\n",
      "2                 43.5     29.6      26.9\n",
      "3                 20.1     23.3      56.5\n",
      "4                  3.5     10.2      86.3\n",
      "5                  0.9      8.9      90.2\n",
      "\n",
      "üìå Topic Distribution:\n",
      "Topic_Label\n",
      "Topic 2.0    22530\n",
      "Topic 4.0    21114\n",
      "Topic 1.0    20417\n",
      "Topic 3.0    18194\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "‚úÖ SENTIMENT ANALYSIS COMPLETE\n",
      "================================================================================\n",
      "\n",
      "üöÄ Next Step: Run Notebook 03 to launch the interactive dashboard!\n"
     ]
    }
   ],
   "source": [
    "# Generate summary statistics\n",
    "print(\"=\"*80)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Global sentiment health\n",
    "global_sentiment = analysis_df['sentiment_score'].mean()\n",
    "print(f\"\\nüå°Ô∏è GLOBAL SENTIMENT HEALTH: {global_sentiment:.3f}\")\n",
    "print(f\"   Scale: -1 (Very Negative) to +1 (Very Positive)\")\n",
    "print(f\"   Interpretation: {'Positive' if global_sentiment > 0 else 'Negative'} overall sentiment\")\n",
    "\n",
    "# Sentiment by rating\n",
    "print(\"\\nüìä AI Sentiment by Star Rating:\")\n",
    "sentiment_by_rating = analysis_df.groupby('score')['ai_sentiment'].value_counts(normalize=True).unstack().fillna(0)\n",
    "print(sentiment_by_rating.round(3) * 100)\n",
    "\n",
    "# Topic distribution\n",
    "if 'Topic_Label' in analysis_df.columns:\n",
    "    print(\"\\nüìå Topic Distribution:\")\n",
    "    print(analysis_df['Topic_Label'].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ SENTIMENT ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nüöÄ Next Step: Run Notebook 03 to launch the interactive dashboard!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
